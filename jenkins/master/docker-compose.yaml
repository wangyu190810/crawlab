version: '3.3'
services:
  master: 
    image: "tikazyq/crawlab:master"
    environment:
      CRAWLAB_API_ADDRESS: "https://crawlab.cn/api"
      CRAWLAB_BASE_URL: "/demo"
      CRAWLAB_SERVER_MASTER: "Y"
      CRAWLAB_SERVER_REGISTER_TYPE: "ip"
      CRAWLAB_SERVER_REGISTER_IP: "172.19.0.1"
      CRAWLAB_MONGO_HOST: "mongo"
      CRAWLAB_REDIS_ADDRESS: "redis"
      CRAWLAB_LOG_PATH: "/var/logs/crawlab"
      CRAWLAB_SETTING_ALLOWREGISTER: "Y"
      CRAWLAB_SERVER_LANG_NODE: "Y"
    ports:    
      - "8080:8080" # frontend
    depends_on:
      - mongo
      - redis
    volumes:
      - "/opt/crawlab/log:/var/logs/crawlab" # log persistent 日志持久化
  worker:
    image: "tikazyq/crawlab:master"
    environment:
      CRAWLAB_SERVER_MASTER: "N"
      CRAWLAB_SERVER_REGISTER_TYPE: "ip"
      CRAWLAB_SERVER_REGISTER_IP: "172.19.0.2"
      CRAWLAB_MONGO_HOST: "mongo"
      CRAWLAB_REDIS_ADDRESS: "redis"
      CRAWLAB_SERVER_LANG_NODE: "Y"
    depends_on:
      - mongo
      - redis
    volumes:
      - "/opt/crawlab/log:/var/logs/crawlab" # log persistent 日志持久化
  mongo:
    image: mongo:latest
    restart: always
    volumes:
      - "/opt/crawlab/mongo/data/db:/data/db"
      - "/opt/crawlab/mongo/tmp:/tmp"
  redis:
    image: redis:latest
    restart: always
    volumes:
      - "/opt/crawlab/redis/data:/data"
  splash:  # use Splash to run spiders on dynamic pages
    image: scrapinghub/splash
    # ports:
    #   - "8050:8050"
